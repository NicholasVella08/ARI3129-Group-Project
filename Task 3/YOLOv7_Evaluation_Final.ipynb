{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6dbdae7",
   "metadata": {},
   "source": [
    "# YOLOv7 model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6873267",
   "metadata": {},
   "source": [
    "The following code loads the YOLOv7 trained model and calculates evaluation metrics based on its perfromance against a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9310bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kyled\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Fusing layers... \n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyled\\anaconda3\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import io\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "yolov7_path = Path(r\"C:\\Users\\kyled\\yolov7\\yolov7\")\n",
    "sys.path.append(str(yolov7_path))\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "from utils.plots import plot_one_box\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    model = attempt_load(model_path, map_location=device)\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "def process_image(image_path, img_size=640):\n",
    "    # Loading the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resizing and padding image\n",
    "    h, w, _ = img.shape\n",
    "    r = img_size / max(h, w) \n",
    "    new_w = int(round(w * r))\n",
    "    new_h = int(round(h * r))\n",
    "    img_resized = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "    img_padded = np.full((img_size, img_size, 3), 128, dtype=np.uint8)\n",
    "    img_padded[(img_size - new_h) // 2:(img_size - new_h) // 2 + new_h, \n",
    "               (img_size - new_w) // 2:(img_size - new_w) // 2 + new_w, :] = img_resized\n",
    "\n",
    "    img_tensor = torch.from_numpy(img_padded).permute(2, 0, 1).float().unsqueeze(0)\n",
    "    img_tensor /= 255.0\n",
    "    return img_tensor\n",
    "\n",
    "def detect_objects(model, img_tensor, device):\n",
    "    # Performing object detection\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_tensor)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
    "    return pred\n",
    "\n",
    "def draw_detections(original_img, img_tensor, detections, class_names, img_size=640):\n",
    "    # Checking if detections are present\n",
    "    if detections is not None:\n",
    "        for i, det in enumerate(detections):\n",
    "            if len(det):\n",
    "                # Rescaling boxes to original image size\n",
    "                det[:, :4] = scale_coords(img_tensor.shape[2:], det[:, :4], original_img.shape).round()\n",
    "\n",
    "                \n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    label_with_conf = f'{class_names[int(cls)]} {conf:.2f}'\n",
    "                    plot_one_box(xyxy, original_img, label=label_with_conf, color=(255, 0, 0), line_thickness=3)\n",
    "\n",
    "    return original_img\n",
    "\n",
    "def parse_label_file(label_path, img_shape):\n",
    "    #Getting ground truth boxes\n",
    "    ground_truth_boxes = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "            x1 = int((x_center - width / 2) * img_shape[1])\n",
    "            y1 = int((y_center - height / 2) * img_shape[0])\n",
    "            x2 = int((x_center + width / 2) * img_shape[1])\n",
    "            y2 = int((y_center + height / 2) * img_shape[0])\n",
    "            ground_truth_boxes.append([x1, y1, x2, y2, class_id])\n",
    "    return ground_truth_boxes\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    #Comparing the detected and true bounding boxes using IoU\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    intersection_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    iou = intersection_area / union_area if union_area != 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    # Creating a matrix from the confusion matrix data\n",
    "    matrix = []\n",
    "    for class_name in class_names:\n",
    "        row = [confusion_matrix[class_name]['TP'], confusion_matrix[class_name]['FP'], confusion_matrix[class_name]['FN']]\n",
    "        matrix.append(row)\n",
    "\n",
    "    matrix = np.array(matrix)\n",
    "\n",
    "    fig_size_width = max(8, len(class_names) * 0.5)\n",
    "    fig_size_height = max(6, len(class_names) * 0.5)\n",
    "    plt.figure(figsize=(fig_size_width, fig_size_height))\n",
    "\n",
    "    ax = sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5)\n",
    "\n",
    "    ax.set_xlabel('Predicted labels', fontsize=12)\n",
    "    ax.set_ylabel('True labels', fontsize=12)\n",
    "    ax.set_title('Confusion Matrix', fontsize=16)\n",
    "    ax.xaxis.set_ticklabels(['True Positive', 'False Positive', 'False Negative'], fontsize=10)\n",
    "    ax.yaxis.set_ticklabels(class_names, fontsize=10, va='center', rotation = 0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "class_names = ['pizza', 'Mushroom', 'Pepperoni', 'Yellow Peppers', 'Black Olives', 'Onion', 'Ham', 'Tomato', 'Broccoli', 'Green Olives']\n",
    "\n",
    "\n",
    "log_dir = r\"C:\\Users\\kyled\\yolov7\\runs\\YOLOv7_tensorboard\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "def main():\n",
    "    yolov7()    \n",
    "    \n",
    "def yolov7():    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_path = r\"C:\\Users\\kyled\\yolov7\\runs\\train\\exp13\\weights\\best.pt\"\n",
    "    test_images_dir = r\"C:\\Users\\kyled\\Downloads\\yolo_formatted_testing_set\\images\"\n",
    "    model = load_model(model_path, device).to(device)\n",
    "\n",
    "    # Initializing counters for overall metrics\n",
    "    total_TP, total_FP, total_FN = 0, 0, 0\n",
    "\n",
    "    # Initializing confusion matrix\n",
    "    confusion_matrix = {class_name: {'TP': 0, 'FP': 0, 'FN': 0} for class_name in class_names}\n",
    "\n",
    "    for image_path in glob.glob(test_images_dir + '/*.jpg'):\n",
    "        original_img = cv2.imread(image_path)\n",
    "        original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "        img_tensor = process_image(image_path)\n",
    "\n",
    "        detections = detect_objects(model, img_tensor.to(device), device)\n",
    "        \n",
    "        label_file = image_path.replace('images', 'Labels').replace('.jpg', '.txt')\n",
    "        ground_truth_boxes = parse_label_file(label_file, original_img.shape)\n",
    "\n",
    "        # Processing detections\n",
    "        for det in detections[0]:\n",
    "            det_box = [int(det[0]), int(det[1]), int(det[2]), int(det[3])]\n",
    "            det_class = int(det[-1])\n",
    "\n",
    "            # Checking if detection matches any ground truth box of the same class\n",
    "            matched = False\n",
    "            for gt_box in ground_truth_boxes:\n",
    "                if det_class == gt_box[4] and calculate_iou(det_box, gt_box[:4]) > 0.5:\n",
    "                    matched = True\n",
    "                    break\n",
    "\n",
    "            if matched:\n",
    "                total_TP += 1\n",
    "                confusion_matrix[class_names[det_class]]['TP'] += 1\n",
    "            else:\n",
    "                total_FP += 1\n",
    "                confusion_matrix[class_names[det_class]]['FP'] += 1\n",
    "\n",
    "        for gt_box in ground_truth_boxes:\n",
    "            gt_class = int(gt_box[4])\n",
    "\n",
    "            detected = False\n",
    "            for det in detections[0]:\n",
    "                det_box = [int(det[0]), int(det[1]), int(det[2]), int(det[3])]\n",
    "                if gt_class == int(det[-1]) and calculate_iou(det_box, gt_box[:4]) > 0.5:\n",
    "                    detected = True\n",
    "                    break\n",
    "\n",
    "            if not detected:\n",
    "                total_FN += 1\n",
    "                confusion_matrix[class_names[gt_class]]['FN'] += 1\n",
    "\n",
    "    # Calculating overall Metrics\n",
    "    precision = total_TP / (total_TP + total_FP) if total_TP + total_FP > 0 else 0\n",
    "    recall = total_TP / (total_TP + total_FN) if total_TP + total_FN > 0 else 0\n",
    "    F1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        \n",
    "        \n",
    "    text_string = f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score: {F1}\"\n",
    "    writer.add_text('Metrics/Summary', text_string)\n",
    "        \n",
    "    writer.add_scalar('YOLOv7 Precision', precision)\n",
    "    writer.add_scalar('YOLOv7 Recall', recall)\n",
    "    writer.add_scalar('YOLOv7 F1-Score', F1)\n",
    "\n",
    "    confusion_matrix_plot = plot_confusion_matrix(confusion_matrix, class_names)\n",
    "    writer.add_figure('YOLOv7 Confusion Matrix', confusion_matrix_plot)\n",
    "\n",
    "    writer.close()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cffb072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "IDetect.fuse\n",
      "Number of pizzas detected: 2\n",
      "Toppings count:\n",
      "  Mushroom: 0\n",
      "  Pepperoni: 22\n",
      "  Yellow Peppers: 0\n",
      "  Black Olives: 0\n",
      "  Onion: 0\n",
      "  Ham: 0\n",
      "  Tomato: 0\n",
      "  Broccoli: 0\n",
      "  Green Olives: 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "def detect_objects(model, img_tensor, device):\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_tensor)[0]\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
    "    \n",
    "    class_indices = [int(detection[-1]) for detection in pred[0]] if pred[0] is not None else []\n",
    "    return pred, class_indices\n",
    "\n",
    "def analyze_detections(class_indices, class_names):\n",
    "    # Counting the occurrences of each class\n",
    "    class_counts = {class_name: 0 for class_name in class_names}\n",
    "    for index in class_indices:\n",
    "        class_name = class_names[index]\n",
    "        class_counts[class_name] += 1\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Set the path to your trained model and test image\n",
    "    model_path = r\"C:\\Users\\kyled\\yolov7\\runs\\train\\exp13\\weights\\best.pt\"\n",
    "    test_image_path = r\"C:\\Users\\kyled\\Downloads\\pizza_test.jpg\"\n",
    "\n",
    "    # Load the model\n",
    "    model = load_model(model_path, device).to(device)\n",
    "\n",
    "    # Load and process the image\n",
    "    original_img = cv2.imread(test_image_path)\n",
    "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    img_tensor = process_image(test_image_path)\n",
    "\n",
    "    # Detect objects\n",
    "    detections, class_indices = detect_objects(model, img_tensor.to(device), device)\n",
    "\n",
    "    # Analyze detections\n",
    "    class_counts = analyze_detections(class_indices, class_names)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Number of pizzas detected: {class_counts['pizza']}\")\n",
    "    print(\"Toppings count:\")\n",
    "    for topping, count in class_counts.items():\n",
    "        if topping != 'pizza':\n",
    "            print(f\"  {topping}: {count}\")\n",
    "\n",
    "    # Draw and display detections\n",
    "    detected_img = draw_detections(original_img, img_tensor, detections, class_names)\n",
    "    Image.fromarray(detected_img).show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
